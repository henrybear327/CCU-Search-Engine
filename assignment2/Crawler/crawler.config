[SITE]
# initial_page crawler starting page
# checking_url checking if it's internal site

# no trailing slash please!

# initial_page = https://www.ettoday.net
# checking_url = ettoday.net

# initial_page = https://www.npr.org
# checking_url = npr.org

initial_page = https://news.ycombinator.com
checking_url = ycombinator.com

[STORAGE]

# database_name = ettoday
# collection_name = data

# database_name = npr
# collection_name = data429

database_name = hackernews
collection_name = data429

# fetched_set_file = ettoday.txt
# fetched_set_file = npr.txt

[RULES]

max_retry = 3
assumed_non_content_depth = 2

# starting level is 0-based
max_overall_depth = 2

##################
# To be implemented
max_internal_depth = 10
max_external_depth_= 1

disregard = ".mp3|.mp4|"
##################


# for highly dynamic sites, debugging
backend = chrome

# for mostly static sites
# backend = requests
# timeout = 5.0

[FOLDER]
page_source = ../page_source/

[DEBUG]

take_screenshot = true
# Crawler config file

[site]
# true = AlexaTopSitesURL 
# false = manualSeedURL
useAlexaTopSites = false
 
AlexaTopSitesURL = "https://www.alexa.com/topsites/countries/TW" # issues with no leading portocal... QQ
# manualSeedFile = "data/seedingSites.txt"
# manualSeedFile = "data/seedingSitesSubset.txt"
# manualSeedFile = "data/small.txt"
manualSeedFile = "data/test.txt"

[system]

maxGoRountinesPerSite = 3

maxConcurrentFetch = 900

maxDistinctPagesToFetchPerSite = 50000
#### maxTotalPagesToFetch = 2500000

# idle time between fetches in second
minFetchTimeInterval = "3s"
# in second, starts counting after preprocessing ends
maxRunningTime = "6h" # starts counting after delayed launching

#### hardReset = false

[chromedp]
# /opt/google/chrome
# /usr/bin/google-chrome
# /opt/google/chrome/google-chrome --headless --remote-debugging-port=9222 --disable-gpu
# alias chrome="/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome"
# /Applications/Google Chrome.app/Contents/MacOS
headlessMode = true

maxConcurrentJobs = 10 # max 5 linux 10

execPath = "google-chrome" # linux
# execPath = "/Applications/Google Chrome Canary.app/Contents/MacOS/Google Chrome Canary" # mac
# execPath = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"

[output]

slowAction = "10s" # ns (1e-9)

# please create the folder manually!

seedfile = "data/currentRunSeedSite.txt"
pageSourcePath = "pageSource/"
screenshotPath = "screenshot/"
saveScreenshot = true
savePageSource = true

[mongodb]

url = "127.0.0.1:27017"
database = "crawler"